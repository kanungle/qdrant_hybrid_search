{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e5f1a5c2",
      "metadata": {
        "id": "e5f1a5c2"
      },
      "source": [
        "# Hybrid Search with Reranking and Filtering\n",
        "_Last updated: June 1, 2025_\n",
        "\n",
        "This notebook demonstrates advanced hybrid search techniques combining three different [embedding](https://en.wikipedia.org/wiki/Word_embedding) approaches: **dense**, **sparse**, and **late interaction**. It uses dense and sparse embeddings for initial retrieval, then late interaction for reranking. It also filters by `user_id` to simulate multitenancy.\n",
        "\n",
        "### What is Hybrid Search?\n",
        "Hybrid search combines multiple retrieval methods to improve search quality and relevance. Instead of relying on a single approach, we leverage the strengths of different embedding techniques:\n",
        "\n",
        "- **Dense Embeddings** (Semantic Search): Uses neural networks to create dense vector representations of unstructured data, capturing semantic meaning and context. Great for finding conceptually similar content.\n",
        "\n",
        "- **Sparse Embeddings** (Keyword Search): Uses keyword-based search through BM25 for finding exact matches in words. It's great for maintaining interpretability and precision, especially in use cases where industry-specific terms are used.\n",
        "\n",
        "- **Late Interaction Embeddings** (Advanced Semantic): Allows each [token](https://en.wikipedia.org/wiki/Text_segmentation#Word_segmentation) to get it's own embedding, enabling precise matching and fine-grained interactions. It combines the benefits of dense retrieval and token-level precision, making it great for reranking in this workflow.\n",
        "\n",
        "**Why?** By combining these three approaches, we get more robustness to different types of queries to the vector database\n",
        "\n",
        "### References and Resources\n",
        "The following were used to complete this project:\n",
        "- [Qdrant Reranking in Hybrid Search](https://qdrant.tech/documentation/advanced-tutorials/reranking-hybrid-search/?q=ingest#ingestion-stage)\n",
        "- [Qdrant 'Concepts' Documentation](https://qdrant.tech/documentation/concepts/)\n",
        "- [How to Build the Ultimate Hybrid Search with Qdrant (video)](https://www.youtube.com/live/LAZOxqzceEU?si=4HF34v9G1xq3Z3-6)\n",
        "- [Anthropic's Claude](https://claude.ai/new) (for coding support like troubleshooting, debugging, cleanup)\n",
        "- [Hugging Face Datasets](https://huggingface.co/datasets?modality=modality:text&sort=trending) (for source documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "323a8135",
      "metadata": {
        "id": "323a8135"
      },
      "source": [
        "## Environment Setup\n",
        "\n",
        "First we install all the required libraries for this notebook:\n",
        "\n",
        "- **qdrant-client**: Qdrant's vector database client for storing and retrieving embeddings\n",
        "- **fastembed**: Qdrant's opensource, lightweight, and comprehensive library for generating different embedding types\n",
        "- **fastembed-gpu**: The version of fastembed that utilizes GPU acceleration (when available)\n",
        "- **tqdm**: Visual progress bars to track long-running operations\n",
        "- **polars**: Fast dataframe library for data manipulation\n",
        "- **torch**: PyTorch for GPU acceleration (when available)\n",
        "- **rerankers**: Comprehensive library of rerankers, including ColBERT\n",
        "\n",
        "We then import all the libraries and modules we need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3922b9bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3922b9bd",
        "outputId": "9fa7ee02-9bf9-4399-994a-bb9331c530f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: qdrant-client in /usr/local/lib/python3.11/dist-packages (1.14.2)\n",
            "Requirement already satisfied: fastembed in /usr/local/lib/python3.11/dist-packages (0.7.0)\n",
            "Requirement already satisfied: fastembed-gpu in /usr/local/lib/python3.11/dist-packages (0.7.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (1.21.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: rerankers in /usr/local/lib/python3.11/dist-packages (0.10.0)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (1.71.0)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (2.0.2)\n",
            "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (2.10.1)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (5.29.4)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (2.11.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (2.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.20 in /usr/local/lib/python3.11/dist-packages (from fastembed) (0.31.4)\n",
            "Requirement already satisfied: loguru<0.8.0,>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from fastembed) (0.7.3)\n",
            "Requirement already satisfied: mmh3<6.0.0,>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from fastembed) (5.1.0)\n",
            "Requirement already satisfied: onnxruntime!=1.20.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from fastembed) (1.22.0)\n",
            "Requirement already satisfied: pillow<12.0.0,>=10.3.0 in /usr/local/lib/python3.11/dist-packages (from fastembed) (11.2.1)\n",
            "Requirement already satisfied: py-rust-stemmers<0.2.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from fastembed) (0.1.5)\n",
            "Requirement already satisfied: requests<3.0,>=2.31 in /usr/local/lib/python3.11/dist-packages (from fastembed) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from fastembed) (0.21.1)\n",
            "Requirement already satisfied: onnxruntime-gpu!=1.20.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from fastembed-gpu) (1.22.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.16.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.2.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (6.0.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (25.2.10)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31->fastembed) (3.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime!=1.20.0,>=1.17.0->fastembed) (10.0)\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "%pip install qdrant-client fastembed fastembed-gpu tqdm polars torch rerankers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "49c2cd1a",
      "metadata": {
        "id": "49c2cd1a"
      },
      "outputs": [],
      "source": [
        "# Import dependencies\n",
        "from qdrant_client import QdrantClient, models\n",
        "from fastembed import TextEmbedding, LateInteractionTextEmbedding, SparseTextEmbedding\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from getpass import getpass\n",
        "import random, os\n",
        "import torch\n",
        "from rerankers import Reranker"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7a3e6f4",
      "metadata": {
        "id": "b7a3e6f4"
      },
      "source": [
        "## Create Embeddings\n",
        "\n",
        "This section covers the creation of two different types of embeddings needed for hybrid search. Each embedding type captures different aspects of the source text:\n",
        "\n",
        "- **Dense embeddings**: Fixed-size vectors, mostly non-zero, capturing semantic meaning\n",
        "- **Sparse embeddings**: Variable-size vectors, mostly zero, capturing keyword term-frequency information."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86f9ef5e",
      "metadata": {
        "id": "86f9ef5e"
      },
      "source": [
        "### Embedding Setup\n",
        "\n",
        "We must first initialize our embedding models, then we can load our document dataset to start embedding. The source documents for this project were **arxiv paper abstracts**, found on [Hugging Face](https://huggingface.co/datasets/bluuebunny/arxiv_abstract_embedding_mxbai_large_v1_milvus_binary) and published by Mitanshu Sukhwani in 2025. This dataset provides a rich corpus of scientific text for demonstrating text retrieval. We random sample 1 million abstracts from this dataset to reduce overall embeddings to the minimum required volume."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e937f1e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e937f1e4",
        "outputId": "5e003dff-1cfb-4d75-b6db-8b0803998b03"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Initialize embedding models\n",
        "dense_embedding_model = TextEmbedding(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "bm25_embedding_model = SparseTextEmbedding(\"Qdrant/bm25\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5eb3d6a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eb3d6a2",
        "outputId": "1bd196ff-9e11-4670-e45e-593ff536197c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (10_000,)\n",
            "Series: 'abstract' [str]\n",
            "[\n",
            "\t\"  Coulomb collisions in partic…\n",
            "\t\"  Reflected light curves obser…\n",
            "\t\"  Our goals are (i) to search …\n",
            "\t\"  To search for possible textu…\n",
            "\t\"  Hartman and Nissim-Sabat hav…\n",
            "\t…\n",
            "\t\"  With the fast development of…\n",
            "\t\"  We propose a new method in w…\n",
            "\t\"  We study the transverse self…\n",
            "\t\"  The integer division of a nu…\n",
            "\t\"  Here we present an algorithm…\n",
            "]\n",
            "Total documents loaded: 10000\n"
          ]
        }
      ],
      "source": [
        "# Load 1 Million Documents (arxiv abstracts)\n",
        "documents = pl.read_parquet('hf://datasets/bluuebunny/arxiv_abstract_embedding_mxbai_large_v1_milvus_binary/**/*.parquet')\n",
        "documents = documents['abstract'].sample(10000)\n",
        "print(documents)\n",
        "print(f\"Total documents loaded: {len(documents)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef4b50b2",
      "metadata": {
        "id": "ef4b50b2"
      },
      "source": [
        "### Generate Actual Embeddings\n",
        "\n",
        "Now that our data and models are prepared, we're ready to start generating embeddings. **This is the most compute intensive task in the workflow, and may take some time to complete!**\n",
        "\n",
        "**Time required on CPU**\n",
        "- Dense Embeddings: ~20 seconds per 1000 docs\n",
        "- Sparse Embeddings: ~1 second per 1000 docs\n",
        "\n",
        "**GPU Usage**\n",
        "\n",
        "Before generating embeddings, we check for GPU availability and set appropriate batch sizes. GPU acceleration significantly speeds up embedding generation, especially for dense embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "sDmIQphr7wUO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDmIQphr7wUO",
        "outputId": "9bfca77c-1cb8-4188-cfd7-97660289b106"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: False\n",
            "GPU count: 0\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Current GPU: {torch.cuda.get_device_name()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ZPPljGG94NyK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPPljGG94NyK",
        "outputId": "a20fddcd-d102-42af-d836-31552fc87a25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size: 32\n"
          ]
        }
      ],
      "source": [
        "# Set batch_sized based on GPU availability\n",
        "if torch.cuda.is_available():\n",
        "    batch_size = 200\n",
        "else:\n",
        "    batch_size = 32\n",
        "\n",
        "print(f\"Batch size: {batch_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b527d84a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b527d84a",
        "outputId": "dc9d267a-06e8-4ce5-ca55-16aebbdf36eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating embeddings...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Dense Embeddings: 100%|██████████| 10000/10000 [02:17<00:00, 72.92doc/s]\n",
            "Sparse Embeddings: 100%|██████████| 10000/10000 [00:02<00:00, 4104.61doc/s]\n"
          ]
        }
      ],
      "source": [
        "# Generate embeddings for all documents; use batching to optimize performance\n",
        "print(\"Generating embeddings...\")\n",
        "\n",
        "def generate_embeddings(model, documents, batch_size=batch_size, desc=\"Embeddings\"):\n",
        "    embeddings = []\n",
        "\n",
        "    with tqdm(total=len(documents), desc=desc, unit=\"doc\") as pbar:\n",
        "        for i in range(0, len(documents), batch_size):\n",
        "            batch = documents[i:i + batch_size]\n",
        "            batch_embeddings = list(model.embed(batch))\n",
        "            embeddings.extend(batch_embeddings)\n",
        "            pbar.update(len(batch))\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "dense_embeddings = generate_embeddings(\n",
        "    dense_embedding_model, documents, batch_size=batch_size, desc=\"Dense Embeddings\"\n",
        ")\n",
        "\n",
        "bm25_embeddings = generate_embeddings(\n",
        "    bm25_embedding_model, documents, batch_size=batch_size, desc=\"Sparse Embeddings\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "643473ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "643473ed",
        "outputId": "639ad4f6-54ed-415b-b953-088b95d3d276"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dense embedding shape: (384,)\n",
            "BM25 embedding type: <class 'fastembed.sparse.sparse_embedding_base.SparseEmbedding'>\n"
          ]
        }
      ],
      "source": [
        "# Check shapes and types\n",
        "print(f\"Dense embedding shape: {dense_embeddings[0].shape}\")\n",
        "print(f\"BM25 embedding type: {type(bm25_embeddings[0])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8960dd57",
      "metadata": {
        "id": "8960dd57"
      },
      "source": [
        "## Using Qdrant Cloud Vector Database\n",
        "\n",
        "Qdrant is a high-performance vector database optimized for similarity search. We're using it because has:\n",
        "\n",
        "- Multi-vector support\n",
        "- Hybrid search\n",
        "- Filtering\n",
        "- Scalability\n",
        "- Performance\n",
        "- Cloud hosting\n",
        "\n",
        "(and of course, because it's required for the project!)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61eae127",
      "metadata": {
        "id": "61eae127"
      },
      "source": [
        "### Setting up Qdrant\n",
        "\n",
        "We are using Qdrant Cloud for this excercise, which requires an endpoint and API key to access the cluster. The code below prompts the user for the information (rather than hardcode, presenting security risks), and then creates a [collection](https://qdrant.tech/documentation/concepts/collections/). A collection is a named set of points (vectors with a payload) among which you can search. Binary quantization is used to reduce memory usage while maintaining search quality. Lastly, a [tenant index](https://qdrant.tech/documentation/guides/multiple-partitions/#configure-multitenancy) is also created to allow filtering by user_id."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a376d412",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a376d412",
        "outputId": "46f048ad-2e80-4c22-a020-c4c492eb6009"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Qdrant endpoint: https://16325403-8fa2-40e5-8236-03ad0b059833.us-west-2-0.aws.cloud.qdrant.io\n",
            "Qdrant API key: ··········\n"
          ]
        }
      ],
      "source": [
        "# Configure up Qdrant endpoint and API key\n",
        "QDRANT_ENDPOINT = (\n",
        "    os.environ[\"QDRANT_ENDPOINT\"]\n",
        "    if \"QDRANT_ENDPOINT\" in os.environ\n",
        "    else input(\"Qdrant endpoint: \")\n",
        ")\n",
        "QDRANT_API_KEY = (\n",
        "    os.environ[\"QDRANT_API_KEY\"]\n",
        "    if \"QDRANT_API_KEY\" in os.environ\n",
        "    else getpass(\"Qdrant API key: \")\n",
        ")\n",
        "\n",
        "COLLECTION_NAME = \"hybrid-search\"\n",
        "\n",
        "# Make connection\n",
        "client = QdrantClient(\n",
        "    url=QDRANT_ENDPOINT,\n",
        "    api_key=QDRANT_API_KEY\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "fffde00a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fffde00a",
        "outputId": "632b7eb0-5d53-4c2f-9fac-56c79fb1417d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deleted existing collection: hybrid-search\n",
            "Created new collection: hybrid-search\n"
          ]
        }
      ],
      "source": [
        "# Delete existing collection if it exists\n",
        "try:\n",
        "    client.delete_collection(COLLECTION_NAME)\n",
        "    print(f\"Deleted existing collection: {COLLECTION_NAME}\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Create collection\n",
        "client.create_collection(\n",
        "    COLLECTION_NAME,\n",
        "    vectors_config={\n",
        "        \"dense\": models.VectorParams(\n",
        "            size=384,\n",
        "            distance=models.Distance.COSINE,\n",
        "            quantization_config=models.BinaryQuantization(\n",
        "                binary=models.BinaryQuantizationConfig(\n",
        "                    always_ram=True\n",
        "                )\n",
        "            )\n",
        "        ),\n",
        "    },\n",
        "    sparse_vectors_config={\n",
        "        \"bm25\": models.SparseVectorParams(modifier=models.Modifier.IDF)\n",
        "    }\n",
        ")\n",
        "print(f\"Created new collection: {COLLECTION_NAME}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "aca56d50",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aca56d50",
        "outputId": "35248570-c041-49ee-c401-9cac751866f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "UpdateResult(operation_id=1, status=<UpdateStatus.COMPLETED: 'completed'>)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create user_id index for filtering\n",
        "client.create_payload_index(\n",
        "    collection_name=COLLECTION_NAME,\n",
        "    field_name=\"user_id\",\n",
        "    field_schema=models.KeywordIndexParams(\n",
        "        type=models.KeywordIndexType.KEYWORD,\n",
        "        is_tenant=True,\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e4f0390",
      "metadata": {
        "id": "1e4f0390"
      },
      "source": [
        "### Point Creation\n",
        "Each \"point\" in Qdrant represents a document with all its associated vectors and metadata:\n",
        "\n",
        "#### Point Structure:\n",
        "- **ID**: Unique identifier for the document  \n",
        "- **Vectors**: Both embedding types stored together  \n",
        "- **Payload**: Document text and metadata (including user_id for filtering)  \n",
        "\n",
        "#### Simulated Multi-User Environment:\n",
        "We're randomly assigning user IDs (`user_1` through `user_10`) to simulate a multi-tenant application where users should only see their own documents.\n",
        "\n",
        "**This structure enables both vector similarity search and metadata filtering in a single query.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1f8200d3",
      "metadata": {
        "id": "1f8200d3"
      },
      "outputs": [],
      "source": [
        "from qdrant_client.models import PointStruct\n",
        "\n",
        "# Point creation\n",
        "points = []\n",
        "for idx, (dense_embedding, bm25_embedding, doc) in enumerate(\n",
        "    zip(dense_embeddings, bm25_embeddings, documents)\n",
        "):\n",
        "    # Generate a random user_id for demo\n",
        "    user_id = f\"user_{random.randint(1, 10)}\"\n",
        "\n",
        "    point = PointStruct(\n",
        "        id=idx,\n",
        "        vector={\n",
        "            \"dense\": dense_embedding.tolist(),\n",
        "            \"bm25\": bm25_embedding.as_object(),\n",
        "        },\n",
        "        payload={\n",
        "            \"document\": doc,\n",
        "            \"user_id\": user_id\n",
        "        }\n",
        "    )\n",
        "    points.append(point)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "638f3b7e",
      "metadata": {
        "id": "638f3b7e"
      },
      "source": [
        "### Ingesting Data with Qdrant\n",
        "\n",
        "Here, we send the data to our Qdrant vector database cluster using a memory-and-network balanced `batch_size` for performance optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "48b9efbc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48b9efbc",
        "outputId": "cc6565ae-3610-48eb-85e0-f3ab39dbd7d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Qdrant: 100%|██████████| 400/400 [00:36<00:00, 10.97it/s]\n"
          ]
        }
      ],
      "source": [
        "# Batch upsert for better performance\n",
        "batch_size = 25\n",
        "for i in tqdm(range(0, len(points), batch_size), desc=\"Uploading to Qdrant\"):\n",
        "    batch = points[i:i + batch_size]\n",
        "    client.upsert(collection_name=COLLECTION_NAME, points=batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c275e64f",
      "metadata": {
        "id": "c275e64f"
      },
      "source": [
        "### Retrieve Vectors from Qdrant\n",
        "\n",
        "Now for the fun stuff! Let's see how well we can retrieve content from Qdrant using a query.\n",
        "\n",
        "The query is both specific and general, with semantic meaning. This is something a traditional database would not be able to handle effectively. The results are filtered for hypothetical `user_3`.\n",
        "\n",
        "#### Query Strategy:\n",
        "1. Convert the query into both dense and sparse embeddings\n",
        "2. Use these embeddings to find candidate documents\n",
        "3. Apply user filtering for security\n",
        "4. Rerank results for optimal relevance  \n",
        "\n",
        "This approach combines the strengths of all three embedding methods while maintaining security boundaries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "340b4579",
      "metadata": {
        "id": "340b4579"
      },
      "outputs": [],
      "source": [
        "# Enter query and user_id filter\n",
        "query = \"What are the most interesting galaxies in the universe?\"\n",
        "target_user_id = \"user_3\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8ae2f59",
      "metadata": {
        "id": "e8ae2f59"
      },
      "source": [
        "The query itself must be converted to an embedding so that Approximate Nearest Neighbor (ANN) search can find the most similar content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3ebbd359",
      "metadata": {
        "id": "3ebbd359"
      },
      "outputs": [],
      "source": [
        "# Embed the query into vector space\n",
        "dense_vectors = next(dense_embedding_model.query_embed(query))\n",
        "sparse_vectors = next(bm25_embedding_model.query_embed(query))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2dc05d1e",
      "metadata": {
        "id": "2dc05d1e"
      },
      "outputs": [],
      "source": [
        "# Create prefetch that will find candidate documents from hybrid search\n",
        "prefetch = [\n",
        "        models.Prefetch(\n",
        "            query=dense_vectors,\n",
        "            using=\"dense\",\n",
        "            limit=50,\n",
        "        ),\n",
        "        models.Prefetch(\n",
        "            query=models.SparseVector(**sparse_vectors.as_object()),\n",
        "            using=\"bm25\",\n",
        "            limit=50,\n",
        "        ),\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5f149098",
      "metadata": {
        "id": "5f149098"
      },
      "outputs": [],
      "source": [
        "# Create user_id filter using the indexed field\n",
        "user_filter = models.Filter(\n",
        "    must=[\n",
        "        models.FieldCondition(\n",
        "            key=\"user_id\",\n",
        "            match=models.MatchValue(value=target_user_id)\n",
        "        )\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "6cb1252c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cb1252c",
        "outputId": "cc45f4b0-ea32-4f77-8628-333548f31259"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved 71 candidates from hybrid search\n"
          ]
        }
      ],
      "source": [
        "# Run hybrid search to get candidates\n",
        "candidates = client.query_points(\n",
        "    COLLECTION_NAME,\n",
        "    prefetch=prefetch,\n",
        "    query=dense_vectors,\n",
        "    using=\"dense\",\n",
        "    with_payload=True,\n",
        "    limit=500,  # Get decent volume of candidates for reranking\n",
        "    query_filter=user_filter\n",
        ")\n",
        "\n",
        "print(f\"Retrieved {len(candidates.points)} candidates from hybrid search\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sssS4nSsOaSo",
      "metadata": {
        "id": "sssS4nSsOaSo"
      },
      "source": [
        "## Reranking\n",
        "The initial hybrid search retrieval casts a wide net quickly, then reranking applies sophisticated scoring to improve the final results. It's faster than running expensive models on our entire corpus, but more accurate than relying only on simple similarity.\n",
        "\n",
        "Here, we first extract candidate documents (with metadata) from our hybrid search results. Then we rerank them using FastEmbed's reranking functionality.\n",
        "\n",
        "**Note:** Not all rerankers create embeddings, but the ColBERT reranker used here does (at a token-level not document-level)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "tKXdp3mvQk0W",
      "metadata": {
        "id": "tKXdp3mvQk0W"
      },
      "outputs": [],
      "source": [
        "# Extract documents and their metadata for reranking\n",
        "candidate_docs = []\n",
        "candidate_metadata = []\n",
        "\n",
        "for point in candidates.points:\n",
        "    candidate_docs.append(point.payload.get('document', ''))\n",
        "    candidate_metadata.append({\n",
        "        'id': point.id,\n",
        "        'score': point.score,\n",
        "        'user_id': point.payload.get('user_id', ''),\n",
        "        'document': point.payload.get('document', '')\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "ZLVKgjNaQoIT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLVKgjNaQoIT",
        "outputId": "25da0b37-93a2-4df0-86a0-1d081dfcf099"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reranking with ColBERT...\n",
            "Loading default colbert model for language en\n",
            "Default Model: colbert-ir/colbertv2.0\n",
            "Loading ColBERTRanker model colbert-ir/colbertv2.0 (this message can be suppressed by setting verbose=0)\n",
            "No device set\n",
            "Using device cpu\n",
            "No dtype set\n",
            "Using dtype torch.float32\n",
            "Loading model colbert-ir/colbertv2.0, this might take a while...\n",
            "Linear Dim set to: 128 for downcasting\n"
          ]
        }
      ],
      "source": [
        "# Rerank the candidate documents from hybrid search\n",
        "print(\"Reranking with ColBERT...\")\n",
        "ranker = Reranker('colbert')\n",
        "reranked_results = ranker.rank(query=query, docs=candidate_docs)\n",
        "\n",
        "# Get top 50 reranked results\n",
        "top_results = reranked_results.top_k(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1eb73c33",
      "metadata": {
        "id": "1eb73c33"
      },
      "source": [
        "### Display Results\n",
        "\n",
        "To better analyze our results, I've cleaned them up here into a pretty format from Polars."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "41edf645",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41edf645",
        "outputId": "5982896d-e1dd-434e-ef3e-628c182bcccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (50, 4)\n",
            "┌──────┬──────────┬─────────┬──────────────────────────────────────────────────────────────────────┐\n",
            "│ id   ┆ score    ┆ user_id ┆ payload                                                              │\n",
            "│ ---  ┆ ---      ┆ ---     ┆ ---                                                                  │\n",
            "│ i64  ┆ f64      ┆ str     ┆ str                                                                  │\n",
            "╞══════╪══════════╪═════════╪══════════════════════════════════════════════════════════════════════╡\n",
            "│ 4942 ┆ 0.711476 ┆ user_3  ┆ We study the globular cluster (GC) systems in three representative   │\n",
            "│      ┆          ┆         ┆ fossil group galaxies: the nearest (NGC6482), the prototype          │\n",
            "│      ┆          ┆         ┆ (NGC1132) and the most massive known to date (ESO306-017). This is   │\n",
            "│      ┆          ┆         ┆ the …                                                                │\n",
            "│ 162  ┆ 0.669475 ┆ user_3  ┆ Dwarf spheroidal galaxies are characterized by a large measured      │\n",
            "│      ┆          ┆         ┆ mass-to-light ratio and are not expected to be the site of           │\n",
            "│      ┆          ┆         ┆ high-luminosity non-thermal high-energy gamma-ray emissions.         │\n",
            "│      ┆          ┆         ┆ Therefore they…                                                      │\n",
            "│ 5232 ┆ 0.659058 ┆ user_3  ┆ In the last dozens of years different data sets revealed the         │\n",
            "│      ┆          ┆         ┆ accelerated expansion of the Universe which is driven by the so      │\n",
            "│      ┆          ┆         ┆ called dark energy, that now dominates the total amount of           │\n",
            "│      ┆          ┆         ┆ matter-energy …                                                      │\n",
            "│ 2289 ┆ 0.596196 ┆ user_3  ┆ Studying galaxies at different cosmic epochs entails several         │\n",
            "│      ┆          ┆         ┆ observational effects that need to be taken into account to compare  │\n",
            "│      ┆          ┆         ┆ populations across a large time span in a consistent manner. We use  │\n",
            "│      ┆          ┆         ┆ a…                                                                   │\n",
            "│ 8810 ┆ 0.585308 ┆ user_3  ┆ We present an entirely new sample of 388 low-mass galaxies ($M_\\star │\n",
            "│      ┆          ┆         ┆ \\leq 10^{10} M_\\odot$) that have spectroscopic signatures indicating │\n",
            "│      ┆          ┆         ┆ the presence of massive black holes (BHs) in the form of act…        │\n",
            "│ …    ┆ …        ┆ …       ┆ …                                                                    │\n",
            "│ 3774 ┆ 0.393962 ┆ user_3  ┆ The brightest events in a time series of cosmological transients     │\n",
            "│      ┆          ┆         ┆ obey an observation time dependence which is often overlooked. This  │\n",
            "│      ┆          ┆         ┆ dependence can be exploited to probe the global properties of ele…   │\n",
            "│ 6329 ┆ 0.393322 ┆ user_3  ┆ Extragalactic proper motions can reveal a variety of cosmological    │\n",
            "│      ┆          ┆         ┆ and local phenomena over a range of angular scales. These include    │\n",
            "│      ┆          ┆         ┆ observer-induced proper motions, such as the secular aberration dr…  │\n",
            "│ 7370 ┆ 0.392769 ┆ user_3  ┆ This is a white paper submitted to the Stars and Stellar Evolution   │\n",
            "│      ┆          ┆         ┆ (SSE) Science Frontier Panel (SFP) of the NRC's 2010 Astronomy and   │\n",
            "│      ┆          ┆         ┆ Astrophysics Decadal Survey. The white paper is endorsed by the …    │\n",
            "│ 5003 ┆ 0.375358 ┆ user_3  ┆ Compilation of papers contributed by the VERITAS Collaboration to    │\n",
            "│      ┆          ┆         ┆ the 32nd International Cosmic Ray Conference, held 11-18 August 2011 │\n",
            "│      ┆          ┆         ┆ in Beijing, China.                                                   │\n",
            "│ 3889 ┆ 0.372221 ┆ user_3  ┆ Abundances of 18 elements are determined for the common              │\n",
            "│      ┆          ┆         ┆ proper-motion pair, HD134439 and HD134440, which shows high [Mn/Fe]  │\n",
            "│      ┆          ┆         ┆ and low [\\alpha/Fe] ratios as compared to normal halo stars.         │\n",
            "│      ┆          ┆         ┆ Moreover, puz…                                                       │\n",
            "└──────┴──────────┴─────────┴──────────────────────────────────────────────────────────────────────┘\n"
          ]
        }
      ],
      "source": [
        "# Combine reranking results with original metadata\n",
        "final_results = []\n",
        "for result in top_results:\n",
        "    original_metadata = candidate_metadata[result.doc_id]\n",
        "    final_results.append({\n",
        "        'id': original_metadata['id'],\n",
        "        'score': result.score,  # ColBERT reranking score\n",
        "        'user_id': original_metadata['user_id'],\n",
        "        'payload': original_metadata['document']\n",
        "    })\n",
        "\n",
        "df = pl.DataFrame(final_results)\n",
        "pl.Config.set_fmt_str_lengths(200) # Show up to 200 characters from abstract\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49fbd4ac",
      "metadata": {
        "id": "49fbd4ac"
      },
      "source": [
        "## Conclusion and Takeaways\n",
        "\n",
        "### What We've Accomplished\n",
        "\n",
        "**Multi-Modal Embeddings**  \n",
        "- Dense embeddings for semantic understanding  \n",
        "- Sparse embeddings for keyword precision  \n",
        "- Late interaction embeddings for fine-grained relevance  \n",
        "\n",
        "**Production-Ready Architecture**  \n",
        "- Scalable vector database with Qdrant  \n",
        "- Efficient batch processing and indexing  \n",
        "- Multi-tenant security with user filtering  \n",
        "\n",
        "**Advanced Search Capabilities**  \n",
        "- Hybrid retrieval combining multiple signals  \n",
        "- Sophisticated ranking and reranking  \n",
        "- Flexible query processing pipeline  \n",
        "\n",
        "### Potential Enhancements\n",
        "\n",
        "- Implement query-time filtering for better performance  \n",
        "- Add caching for frequently accessed embeddings\n",
        "- Parallelize long-running processes for faster execution\n",
        "- Integrate with LLMs for a more conversation experience (RAG)\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "1. **Hybrid approaches outperform single methods** by combining different strengths  \n",
        "2. **Late interaction models** provide exceptional precision for text search  \n",
        "3. **Vector databases** enable sophisticated multi-modal search at scale  \n",
        "4. **Security considerations** are crucial for multi-tenant applications  \n",
        "\n",
        "This hybrid search system provides a solid foundation for building production-grade search applications that deliver both high recall and precision across diverse query types.\n",
        "\n",
        "Thanks for the fun project!\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
